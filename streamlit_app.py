import streamlit as st
import google.generativeai as genai
import json
import pandas as pd
import time
import re
from datetime import datetime

# ==============================================================================
# 1. CONFIGURACI√ìN DE P√ÅGINA Y ESTILOS
# ==============================================================================
st.set_page_config(
    layout="wide", 
    page_title="Sistema de Traducci√≥n Isom√≥rfica", 
    page_icon="üõ°Ô∏è"
)

st.markdown("""
<style>
    .stTextArea textarea { font-family: 'Courier New', monospace; font-size: 16px; }
    .status-box { padding: 15px; border-radius: 8px; margin-bottom: 10px; border: 1px solid #ddd; }
    .status-nuevo { background-color: #e3f2fd; border-color: #90caf9; color: #0d47a1; }
    .status-conflicto { background-color: #ffebee; border-color: #ef9a9a; color: #b71c1c; }
    .status-ok { background-color: #e8f5e9; border-color: #a5d6a7; color: #1b5e20; }
    .metric-card { background-color: #f8f9fa; padding: 10px; border-radius: 5px; border: 1px solid #eee; text-align: center; }
</style>
""", unsafe_allow_html=True)

# ==============================================================================
# 2. GESTI√ìN DE ESTADO (SESSION STATE)
# ==============================================================================
if "glosario" not in st.session_state:
    # { "token": { "target": "traducci√≥n", "tipo": "CATEGORIA", "fecha": "YYYY-MM-DD" } }
    st.session_state.glosario = {} 

if "estado_actual" not in st.session_state:
    st.session_state.estado_actual = "ESPERANDO_INPUT" # Estados: ESPERANDO_INPUT, CUSTODIA, FINALIZADO

if "datos_temporales" not in st.session_state:
    st.session_state.datos_temporales = None

# ==============================================================================
# 3. LA CONSTITUCI√ìN (SYSTEM PROMPT)
# ==============================================================================
SYSTEM_INSTRUCTION = """
ERES EL MOTOR DE PROCESAMIENTO DE UN SISTEMA DE TRADUCCI√ìN ISOM√ìRFICA (P1-P11).
TU OBJETIVO ES CUMPLIR ESTRICTAMENTE LOS PROTOCOLOS. NO SEAS CONVERSACIONAL.

--- PROTOCOLOS FUNDAMENTALES ---
P1 (ISOMORFISMO): La traducci√≥n debe mantener una correspondencia 1:1 estricta con los tokens fuente.
P2 (AUTORIDAD): El Usuario (P0) es la autoridad. Ante duda o palabra desconocida, marca CONFLICTO/NUEVO.
P4 (N√öCLEOS): Sustantivos, Verbos, Adjetivos son INVARIABLES una vez fijados en el Glosario.
    - Prioridad: Etimolog√≠a > Uso T√©cnico.
    - Si no existe ra√≠z: Usar Transliteraci√≥n + Sufijo Espa√±ol.
P5 (PART√çCULAS): Preposiciones/Conjunciones son POLIVALENTES (dependen de la funci√≥n).
P8 (GLOSARIO): 
    - Consultar SIEMPRE el glosario inyectado.
    - Si el token est√° en el glosario, USAR esa traducci√≥n OBLIGATORIAMENTE.
    - Si el token es nuevo, proponer traducci√≥n basada en etimolog√≠a.

--- INSTRUCCIONES DE SALIDA (JSON) ---
Responde √öNICAMENTE con un objeto JSON v√°lido con esta estructura:

{
  "analisis": [
    {
      "token_origen": "palabra_fuente",
      "token_destino_propuesto": "palabra_destino",
      "categoria": "NUCLEO" | "PARTICULA" | "LOCUCION",
      "razonamiento": "Breve explicaci√≥n etimol√≥gica o regla aplicada",
      "estado": "OK" | "CONFLICTO" | "NUEVO"
    }
  ],
  "traduccion_borrador": "La frase completa traducida",
  "requiere_custodia": true | false
}

REGLA DE ORO: Si encuentras un N√öCLEO que no est√° en el glosario, marca estado="NUEVO" y requiere_custodia=true.
"""

# ==============================================================================
# 4. L√ìGICA DEL N√öCLEO (API & PROCESAMIENTO)
# ==============================================================================

def limpiar_json(texto_respuesta):
    """Limpia bloques de c√≥digo Markdown si Gemini los incluye."""
    if "```json" in texto_respuesta:
        texto_respuesta = texto_respuesta.replace("```json", "").replace("```", "")
    elif "```" in texto_respuesta:
        texto_respuesta = texto_respuesta.replace("```", "")
    return texto_respuesta.strip()

def obtener_glosario_formateado():
    """Convierte el glosario de memoria a texto para el prompt."""
    if not st.session_state.glosario:
        return "GLOSARIO VAC√çO (No hay t√©rminos registrados)."
    
    texto = "GLOSARIO ACTUAL (OBLIGATORIO RESPETAR):\n"
    for token, datos in st.session_state.glosario.items():
        texto += f"- {token} --> {datos['target']} ({datos['tipo']})\n"
    return texto

def consultar_gemini_seguro(prompt_usuario, api_key, modelo):
    """
    Realiza la consulta a la API con manejo robusto de errores 429 (Rate Limits)
    y limpieza de JSON.
    """
    genai.configure(api_key=api_key)
    
    prompt_completo = f"""
    {obtener_glosario_formateado()}
    
    INPUT DEL USUARIO (TEXTO FUENTE A TRADUCIR):
    "{prompt_usuario}"
    
    Analiza token por token. Verifica contra el glosario. Genera el JSON de respuesta.
    """

    # Configuraci√≥n de generaci√≥n para forzar JSON (donde sea soportado) o texto estructurado
    generation_config = {
        "temperature": 0.1, # Baja temperatura para mayor precisi√≥n
        "response_mime_type": "application/json"
    }

    model = genai.GenerativeModel(
        model_name=modelo,
        system_instruction=SYSTEM_INSTRUCTION,
        generation_config=generation_config
    )

    # Bucle de reintentos (Backoff Exponencial)
    max_intentos = 3
    espera_inicial = 2

    for intento in range(max_intentos):
        try:
            with st.spinner(f"Gemini ({modelo}) procesando protocolos... (Intento {intento+1})"):
                response = model.generate_content(prompt_completo)
                
                # Validaci√≥n y Limpieza
                texto_limpio = limpiar_json(response.text)
                return json.loads(texto_limpio)
                
        except Exception as e:
            error_msg = str(e)
            
            # Manejo espec√≠fico de error 429 (Too Many Requests)
            if "429" in error_msg:
                wait_time = espera_inicial * (2 ** intento) # 2s, 4s, 8s
                st.toast(f"‚è≥ Tr√°fico alto en API (Error 429). Reintentando en {wait_time}s...", icon="‚ö†Ô∏è")
                time.sleep(wait_time)
                continue # Volver al inicio del bucle
            
            # Manejo de error 404 (Modelo no encontrado)
            elif "404" in error_msg:
                st.error(f"‚ùå El modelo '{modelo}' no est√° disponible o no es compatible en esta ruta. Por favor selecciona otro modelo de la lista.")
                return None
            
            # Otros errores
            else:
                st.error(f"Error inesperado en Gemini: {error_msg}")
                return None
    
    st.error("‚ùå Se agotaron los reintentos. El servicio est√° saturado temporalmente.")
    return None

def registrar_en_glosario(token, traduccion, categoria):
    """Guarda un t√©rmino validado en el glosario."""
    st.session_state.glosario[token] = {
        "target": traduccion,
        "tipo": categoria,
        "fecha": datetime.now().strftime("%Y-%m-%d %H:%M")
    }

# ==============================================================================
# 5. INTERFAZ DE USUARIO (SIDEBAR)
# ==============================================================================
with st.sidebar:
    st.header("‚öôÔ∏è Configuraci√≥n del Motor")
    
    api_key_input = st.text_input("Gemini API Key", type="password")
    
    # LISTA EXACTA PROPORCIONADA POR EL USUARIO
    modelos_disponibles = [
        "gemini-flash-latest",            # <--- RECOMENDADO (Alias estable)
        "gemini-flash-lite-latest",
        "gemini-2.0-flash-lite",          # <--- RECOMENDADO (Bajo consumo)
        "gemini-2.0-flash",               # Potente pero estricto con cuotas
        "gemini-2.0-flash-001",
        "gemini-2.5-flash",               # Preview (puede ser lento)
        "gemini-2.5-flash-lite",
        "gemini-2.5-pro",
        "gemini-exp-1206",
        "gemini-pro-latest",
        "gemini-3-flash-preview",         # Preview v3
        "gemma-3-27b-it"
    ]
    
    # Selecci√≥n de modelo con un default seguro (Flash Latest)
    modelo_seleccionado = st.selectbox(
        "Modelo Activo", 
        modelos_disponibles, 
        index=0, 
        help="Si recibes errores 429, usa versiones 'Lite' o 'Latest'."
    )
    
    st.divider()
    
    # Panel de Glosario
    st.subheader(f"üìö Glosario ({len(st.session_state.glosario)})")
    if st.session_state.glosario:
        # Convertir a DF para visualizaci√≥n limpia
        data_glosario = []
        for k, v in st.session_state.glosario.items():
            data_glosario.append({"Token": k, "Traducci√≥n": v["target"], "Tipo": v["tipo"]})
        st.dataframe(pd.DataFrame(data_glosario), hide_index=True, use_container_width=True)
        
        col_g1, col_g2 = st.columns(2)
        with col_g1:
            if st.button("Descargar JSON"):
                st.download_button(
                    label="üì• JSON",
                    data=json.dumps(st.session_state.glosario, indent=2),
                    file_name="glosario_isomorfico.json",
                    mime="application/json"
                )
        with col_g2:
            if st.button("üóëÔ∏è Borrar Todo"):
                st.session_state.glosario = {}
                st.rerun()
    else:
        st.info("El glosario est√° vac√≠o. Se llenar√° autom√°ticamente al procesar textos.")

# ==============================================================================
# 6. INTERFAZ PRINCIPAL (WORKFLOW)
# ==============================================================================
st.title("üõ°Ô∏è Sistema de Traducci√≥n Isom√≥rfica")
st.caption(f"Operando con: **{modelo_seleccionado}** | Protocolos P1-P11 Activos")

# --- FASE 1: INPUT ---
if st.session_state.estado_actual == "ESPERANDO_INPUT":
    st.markdown("### 1. Entrada de Texto Fuente")
    texto_usuario = st.text_area("Ingresa el texto (√Årabe, T√©cnico, Filos√≥fico):", height=150)
    
    col_act1, col_act2 = st.columns([1, 4])
    with col_act1:
        if st.button("üöÄ PROCESAR", type="primary", use_container_width=True):
            if not api_key_input:
                st.error("‚ö†Ô∏è Se requiere API Key en la barra lateral.")
            elif not texto_usuario.strip():
                st.warning("‚ö†Ô∏è El texto est√° vac√≠o.")
            else:
                # LLAMADA AL N√öCLEO
                respuesta = consultar_gemini_seguro(texto_usuario, api_key_input, modelo_seleccionado)
                
                if respuesta:
                    st.session_state.datos_temporales = respuesta
                    
                    # Decisi√≥n de Flujo: ¬øCustodia o Directo?
                    if respuesta.get("requiere_custodia", False):
                        st.session_state.estado_actual = "CUSTODIA"
                    else:
                        # Si es todo OK, registramos lo NUEVO autom√°ticamente y finalizamos
                        count_nuevos = 0
                        for item in respuesta.get("analisis", []):
                            if item["estado"] == "NUEVO":
                                registrar_en_glosario(item["token_origen"], item["token_destino_propuesto"], item["categoria"])
                                count_nuevos += 1
                        
                        if count_nuevos > 0:
                            st.toast(f"Se registraron {count_nuevos} t√©rminos nuevos autom√°ticamente.", icon="üìö")
                        
                        st.session_state.estado_actual = "FINALIZADO"
                    
                    st.rerun()

# --- FASE 2: CUSTODIA (HUMAN IN THE LOOP) ---
elif st.session_state.estado_actual == "CUSTODIA":
    st.markdown("### 2. Panel de Custodia (P0)")
    st.warning("‚ö†Ô∏è Gemini ha detectado t√©rminos nuevos o conflictos que requieren tu autorizaci√≥n.")
    
    datos = st.session_state.datos_temporales
    analisis = datos.get("analisis", [])
    
    # Formulario para resolver conflictos
    with st.form("form_custodia"):
        items_a_revisar = [it for it in analisis if it["estado"] in ["NUEVO", "CONFLICTO"]]
        
        if not items_a_revisar:
            st.info("No hay conflictos reales, aunque el sistema marc√≥ custodia. Puedes avanzar.")
        
        for i, item in enumerate(items_a_revisar):
            # Tarjeta visual para cada conflicto
            clase_css = "status-nuevo" if item["estado"] == "NUEVO" else "status-conflicto"
            icono = "üÜï" if item["estado"] == "NUEVO" else "‚öîÔ∏è"
            
            st.markdown(f"""
            <div class="status-box {clase_css}">
                <strong>{icono} {item['estado']}:</strong> Token origen <code>{item['token_origen']}</code> ({item['categoria']})<br>
                <em>Raz√≥n AI: {item['razonamiento']}</em>
            </div>
            """, unsafe_allow_html=True)
            
            col_c1, col_c2 = st.columns([1, 1])
            with col_c1:
                # Mostramos la propuesta de la IA
                st.text_input(f"Propuesta IA ({i})", value=item['token_destino_propuesto'], disabled=True, key=f"prop_{i}")
            with col_c2:
                # Campo editable para la decisi√≥n humana
                st.text_input(f"Tu Decisi√≥n Final ({i})", value=item['token_destino_propuesto'], key=f"dec_{i}")
            
            st.divider()

        # Botones de acci√≥n
        col_submit1, col_submit2 = st.columns([1, 4])
        with col_submit1:
            if st.form_submit_button("‚úÖ APROBAR Y SELLAR", type="primary"):
                # Procesar decisiones
                for i, item in enumerate(items_a_revisar):
                    # Recuperar el valor del input con la key din√°mica
                    valor_final = st.session_state.get(f"dec_{i}", item['token_destino_propuesto'])
                    
                    # Actualizar en Glosario
                    registrar_en_glosario(item['token_origen'], valor_final, item['categoria'])
                    
                    # Actualizar en los datos temporales para el renderizado final
                    # (Buscamos el item original en la lista completa por referencia)
                    item['token_destino_propuesto'] = valor_final
                    item['estado'] = "OK" # Ya resuelto
                
                st.session_state.estado_actual = "FINALIZADO"
                st.rerun()

# --- FASE 3: RESULTADO FINAL ---
elif st.session_state.estado_actual == "FINALIZADO":
    st.markdown("### 3. Traducci√≥n Final (Isom√≥rfica)")
    
    datos = st.session_state.datos_temporales
    
    # Reconstrucci√≥n del texto a partir de los tokens procesados
    # Esto asegura que lo que ves es exactamente lo que se analiz√≥ + tus correcciones
    tokens_finales = [item["token_destino_propuesto"] for item in datos["analisis"]]
    texto_final = " ".join(tokens_finales)
    
    st.success(texto_final)
    
    # Visualizaci√≥n detallada
    with st.expander("üîç Ver Matriz de An√°lisis Detallada"):
        df = pd.DataFrame(datos["analisis"])
        st.dataframe(df, use_container_width=True)

    st.divider()
    
    col_fin1, col_fin2, col_fin3 = st.columns([1, 1, 3])
    with col_fin1:
        if st.button("üîÑ Traducir Otro Texto"):
            st.session_state.estado_actual = "ESPERANDO_INPUT"
            st.session_state.datos_temporales = None
            st.rerun()
            
    with col_fin2:
        st.download_button(
            label="üìÑ Descargar TXT",
            data=texto_final,
            file_name="traduccion_isomorfica.txt",
            mime="text/plain"
        )
